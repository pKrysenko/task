{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files11\\Anaconda\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from math import pi\n",
    "from tensorflow import gfile\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.python.saved_model import tag_constants\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Путь к папке с данными, которые находятся в виде картинок и сгрупированы по папкам\n",
    "# с числами, к которыми эти картинки являются.\n",
    "# Этот путь используется в методе для улучшения нашего набора данных\n",
    "data_path = \"C:/Users/pyroman/dataset/\"\n",
    "epoch = 50\n",
    "label_to_index_map = {}\n",
    "IMAGE_SIZE = 100\n",
    "learning_rate = 0.0001\n",
    "batch_size = 100\n",
    "max_checks_without_progress = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Перегон массивов numpy в tf.tensor для дальнейших преобразований\n",
    "def get_imgs_tf(imgs) :\n",
    "    X_tf = []\n",
    "    for img in imgs :\n",
    "        tf_img = tf.convert_to_tensor(img)\n",
    "        X_tf.append(tf_img)\n",
    "    return X_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Сохранение каждой картинки в виде массива numpy с сохранием одного канала\n",
    "def saving_data(data, label, data_path=data_path) :\n",
    "    global aug_data_path\n",
    "    aug_data_path = os.path.join(data_path, \"aug_data\")\n",
    "    aug_path_imgs = os.path.join(aug_data_path, label)\n",
    "    os.makedirs(aug_path_imgs)\n",
    "    i = 0\n",
    "    for img in data :\n",
    "        i+=1\n",
    "        img = np.squeeze(img, 2)\n",
    "        np.save(aug_path_imgs + \"/\"+str(i)+\".npy\", img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Улучшение набора данных путем увеличения количества тренировочных/проверочных\n",
    "#что достигается путем многократных поворотов на некоторые углы и отзеркаливания\n",
    "def get_aug_imgs(RGBimgs, label) :  \n",
    "    imgs = []\n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "    with tf.Session() as sess:\n",
    "        for img in RGBimgs :\n",
    "            convert = tf.image.rgb_to_grayscale(img)\n",
    "            conv_img = sess.run(convert)\n",
    "            resize = tf.image.resize_images(conv_img, [88, 88])\n",
    "            imgs.append(sess.run(resize))\n",
    "            \n",
    "    tf_imgs = get_imgs_tf(imgs)\n",
    "    with tf.Session() as sess :\n",
    "        for img in tf_imgs :\n",
    "            aug3rd = tf.contrib.image.rotate(img, 15 * pi / 180)\n",
    "            third_stage_aug = sess.run(aug3rd)\n",
    "            imgs.append(third_stage_aug)\n",
    "            \n",
    "    tf.reset_default_graph()         \n",
    "    tf_imgs = get_imgs_tf(imgs)\n",
    "    with tf.Session() as sess :\n",
    "        for img in tf_imgs :\n",
    "            aug4th = tf.contrib.image.rotate(img, 335 * pi / 180)\n",
    "            fourth_stage_aug = sess.run(aug4th)\n",
    "            imgs.append(fourth_stage_aug)\n",
    "            \n",
    "    #В случае римской четверки и шестерки, после отзеркаливания они будут совпадать,\n",
    "    #поэтому вместо отзеркаливания я делаю лишний поворот\n",
    "    if (label == '4') | (label == '6') :\n",
    "        tf.reset_default_graph()         \n",
    "        tf_imgs = get_imgs_tf(imgs)\n",
    "        with tf.Session() as sess :\n",
    "            for img in tf_imgs :\n",
    "                aug4th = tf.contrib.image.rotate(img, 20 * pi / 180)\n",
    "                fourth_stage_aug = sess.run(aug4th)\n",
    "                imgs.append(fourth_stage_aug)\n",
    "    else :\n",
    "        tf.reset_default_graph()\n",
    "        tf_imgs = get_imgs_tf(imgs)\n",
    "        with tf.Session() as sess :\n",
    "            for img in tf_imgs :\n",
    "                aug1st = tf.image.flip_left_right(img)\n",
    "                first_stage_aug = sess.run(aug1st)\n",
    "                imgs.append(first_stage_aug)\n",
    "            \n",
    "    tf.reset_default_graph()         \n",
    "    tf_imgs = get_imgs_tf(imgs)\n",
    "    with tf.Session() as sess :\n",
    "        for img in tf_imgs :\n",
    "            aug2nd = tf.contrib.image.rotate(img, 40 * pi / 180)\n",
    "            second_stage_aug = sess.run(aug2nd)\n",
    "            imgs.append(second_stage_aug)\n",
    "            \n",
    "    tf.reset_default_graph()         \n",
    "    tf_imgs = get_imgs_tf(imgs)\n",
    "    with tf.Session() as sess :\n",
    "        for img in tf_imgs :\n",
    "            aug5th = tf.contrib.image.rotate(img, 310 * pi / 180)\n",
    "            fifth_stage_aug = sess.run(aug5th)\n",
    "            imgs.append(fifth_stage_aug)\n",
    "    \n",
    "    tf.reset_default_graph()         \n",
    "    tf_imgs = get_imgs_tf(imgs)\n",
    "    with tf.Session() as sess :\n",
    "        for img in tf_imgs :\n",
    "            aug6th = tf.contrib.image.rotate(img, 15 * pi / 180)\n",
    "            sixth_stage_aug = sess.run(aug6th)\n",
    "            imgs.append(sixth_stage_aug)\n",
    "    \n",
    "    return imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Основной метод для улучшения тренировочных и проверочных данных.\n",
    "#На вход подается путь к папке с данными, которые должны находится\n",
    "#В виде папка(имя папки - число) и внутри изображения формата .jpg\n",
    "def get_aug_data(path) :\n",
    "    labels = os.listdir(path)\n",
    "    index = 0\n",
    "    for label in labels :\n",
    "        label_to_index_map[label] = index\n",
    "        print(label_to_index_map)\n",
    "        index+=1\n",
    "        X= []\n",
    "        path_folder = os.path.join(path, label)\n",
    "        names_img = os.listdir(path_folder)\n",
    "        for img in names_img :\n",
    "            X_img = os.path.join(path_folder, img)\n",
    "            image = mpimg.imread(X_img)\n",
    "            X.append(image)\n",
    "            \n",
    "        aug_imgs = get_aug_imgs(X, label)\n",
    "        saving_data(aug_imgs, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Реализация one-hot encoding для разметки\n",
    "def encoding_labels(label) :\n",
    "    encoding = [0] * len(label_to_index_map)\n",
    "    encoding[label_to_index_map[label]] = 1\n",
    "    return encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Способ загрузки данных, которые находятся в формате .npy\n",
    "#Также этот метод разбивает данные на тренировочные и проверочные\n",
    "#в отношении (1-k)/k и возвращает сразу готовые данные(данные и разметка)\n",
    "def get_train_and_test_data(path, k) :\n",
    "    y = []\n",
    "    X = []\n",
    "    path = os.path.join(path, '*', '*.npy')\n",
    "    npimgs = gfile.Glob(path)\n",
    "    i=0\n",
    "    for npimg in npimgs :\n",
    "        i+=1\n",
    "        _, label = os.path.split(os.path.dirname(npimg))\n",
    "        img = np.load(npimg)\n",
    "        X.append(img)\n",
    "        y.append(encoding_labels(label))\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = k, random_state = 42)   \n",
    "        \n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Сохраняет приготовленные для тренировки и проверки данные в формате numpy  массивов\n",
    "#по указаному пути path\n",
    "def save_prepared_data(X_train, y_train, X_test, y_test, path) :\n",
    "    np.save(os.path.join(path, \"train_data.npy\"), X_train)\n",
    "    np.save(os.path.join(path, \"train_labels.npy\"), y_train)\n",
    "    np.save(os.path.join(path, \"test_data.npy\"), X_test)\n",
    "    np.save(os.path.join(path, \"train_labels.npy\"), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_prepared_data(path) :\n",
    "    X_train = np.load(os.path.join(path, \"train_data.npy\"))\n",
    "    y_train = np.load(os.path.join(path, \"train_labels.npy\"))\n",
    "    X_test = np.load(os.path.join(path, \"test_data.npy\"))\n",
    "    y_test = np.load(os.path.join(path, \"test_labels.npy\"))\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Определяем нашу нейронную сеть:\n",
    "# Первый сверточный слой принимает на вход массив 88х88, применяет 8 фильтров 5х5\n",
    "# с функцией активации ReLU\n",
    "# Первый объеденяющий слой по максимуму со страйдом 2\n",
    "# Второй сверточный слой принимает на вход массив 44х44, применяет 16 фильтров 5х5\n",
    "# с функцией активации ReLU\n",
    "# Второй объеденяющий слой по максимуму со страйдом 2\n",
    "# Третий сверточный слой принимает на вход массив 22х22, применяет 32 фильтра 5х5\n",
    "# с функцией активации ReLU\n",
    "# Третий объеденяющий слой по максимуму со страйдом 2\n",
    "# Первый полносвязный слой со входным количесвтом нейронов 3872 и выходным 3000\n",
    "# с функцией активации ReLU\n",
    "# Первый полносвязный слой со входным количесвтом нейронов 3000 и выходным 1500\n",
    "# с функцией активации ReLU\n",
    "# Второй полносвязный слой со входным количесвтом нейронов 1500 и выходным 700\n",
    "# с функцией активации ReLU и dropout rate, который можно задать самостоятельно(моя модель имела dropout 0.5 при тренировке)\n",
    "# Третий полносвязный слой со входным количесвтом нейронов 750 и выходным 100\n",
    "# с функцией активации ReLU и dropout rate, который можно задать самостоятельно(моя модель имела dropout 0.5 при тренировке)\n",
    "# Logits слой, с выходным количесвтом нейронов 8, 1 на каждый класс\n",
    "\n",
    "\n",
    "def cnn_model(features, dropout) :\n",
    "  # Input Layer\n",
    "    input_layer = tf.reshape(features, [-1, 88, 88, 1])\n",
    "    \n",
    "    print(type(input_layer))\n",
    "\n",
    "  #Первый сверточный слой\n",
    "    conv1 = tf.layers.conv2d(\n",
    "      inputs=input_layer,\n",
    "      filters=8,\n",
    "      kernel_size=[5, 5],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "\n",
    "  # Pooling Layer #1\n",
    "    pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
    "\n",
    "  # Convolutional Layer #2 and Pooling Layer #2\n",
    "    conv2 = tf.layers.conv2d(\n",
    "      inputs=pool1,\n",
    "      filters=16,\n",
    "      kernel_size=[5, 5],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "    pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
    "\n",
    "    conv3 = tf.layers.conv2d(\n",
    "      inputs=pool2,\n",
    "      filters=32,\n",
    "      kernel_size=[5, 5],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "    pool3 = tf.layers.max_pooling2d(inputs=conv3, pool_size=[2, 2], strides=2)\n",
    "\n",
    "  # Dense Layer\n",
    "    pool2_flat = tf.reshape(pool3, [-1, 11 * 11 * 32])\n",
    "    dense = tf.layers.dense(inputs=pool2_flat, units=3000, activation=tf.nn.relu)\n",
    "    \n",
    "    dense1 = tf.layers.dense(inputs=dense, units=1500, activation=tf.nn.relu)\n",
    "    \n",
    "    dense2 = tf.layers.dense(inputs=dense1, units=750, activation=tf.nn.relu)\n",
    "    \n",
    "    drop2 = tf.layers.dropout(inputs = dense2, rate = dropout)\n",
    "    \n",
    "    dense3 = tf.layers.dense(inputs=drop2, units=100, activation=tf.nn.relu)\n",
    "    \n",
    "  # Logits Layer\n",
    "    logits = tf.layers.dense(inputs=dense3, units=8)\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Тренировка нейронной сети, на вход подаются уже готовые данные, на выходе показывается среднее значение точности\n",
    "# за все итерации в эпохе.\n",
    "# В качестве оптимизатора используется Adam.\n",
    "# Защита от переобучения dropout + техника ранней остановки\n",
    "def train(X_train, y_train, X_test, y_test) :\n",
    "    tf.reset_default_graph()\n",
    "    i = 1\n",
    "    X = tf.placeholder(tf.float32, shape=(None, 88, 88), name=\"input\")\n",
    "    y = tf.placeholder(tf.int32, shape=(None, 8), name=\"labels\")\n",
    "    \n",
    "    dropout = tf.placeholder(tf.float32, name=\"dropout\")\n",
    "    \n",
    "    logits = cnn_model(X, dropout)\n",
    "    \n",
    "    with tf.name_scope(\"loss\") :\n",
    "        loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y, logits=logits))\n",
    "        \n",
    "    with tf.name_scope(\"train\") :\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate)\n",
    "        train_step = optimizer.minimize(loss)\n",
    "        \n",
    "    with tf.name_scope(\"accuracy\") :\n",
    "        predicted = tf.argmax(logits, 1, name=\"prediction\")\n",
    "        truth = tf.argmax(y, 1)\n",
    "        classif = tf.nn.softmax(logits, name=\"classification\")\n",
    "        correct_prediction = tf.equal(predicted, truth)\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32), name=\"accuracy\")\n",
    "        \n",
    "    with tf.Session() as sess :\n",
    "        saver = tf.train.Saver()\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        print(\"Поехали\\n\")\n",
    "        best_acc = 0\n",
    "        number = len(X_train)\n",
    "        start_time = time.time()\n",
    "        for i in range(epoch) :\n",
    "            X_train, y_train = shuffle(X_train, y_train, random_state=42)\n",
    "            for l in range(0, number, batch_size) :\n",
    "                end = l + batch_size\n",
    "                X_batch, y_batch = X_train[l:end], y_train[l:end]\n",
    "                sess.run(train_step, feed_dict = {X: X_batch, y: y_batch, dropout: 0.5})\n",
    "                \n",
    "            num_examples = len(X_test)\n",
    "            total_accuracy = 0\n",
    "            for k in range(0, num_examples,batch_size) :\n",
    "                X_batchT, y_batchT = X_test[k:k+batch_size], y_test[k:k+batch_size]\n",
    "                res_accuracy = sess.run(accuracy, feed_dict={X: X_batchT, y: y_batchT, dropout:0})\n",
    "                total_accuracy += (res_accuracy * len(X_batchT))\n",
    "                \n",
    "            #Техника ранней остановки - если нейронная сеть на проверочных данных не показывает\n",
    "            #лучший результат в течении некоторого количества шагов(max_checks_without_progress)\n",
    "            #то сохраняется модель с наилучшим результатом точности\n",
    "            \n",
    "            if total_accuracy / num_examples > best_acc :\n",
    "                i+=1\n",
    "                saver.save(sess, \"./bestmodel\")\n",
    "                best_acc = total_accuracy / num_examples\n",
    "                checks_without_saves = 0\n",
    "            else:\n",
    "                checks_without_saves+=1\n",
    "                \n",
    "            if checks_without_saves > max_checks_without_progress:\n",
    "                print(\"Early stopping!\")\n",
    "                break\n",
    "            print(\"Epoch:\", i, \" best accuracy:\",\n",
    "                  best_acc * 100, \" current accuracy:\", (total_accuracy / num_examples) * 100)\n",
    "        print(\"\\nTotal training time\", time.time()-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Оценка готовой модели, также сюда передается набор тестовых данных и разметки,\n",
    "# передается путь к модели для проверки в этот метод,\n",
    "# вид этого пути \"..../bestmodel\".\n",
    "# Этот метод выводит среднюю ошибку по всему набору проверочных данных\n",
    "def evaluate(X_test, y_test, path_to_model) :\n",
    "    tf.reset_default_graph()\n",
    "    saver = tf.train.import_meta_graph(path_to_model+\".meta\")\n",
    "    with tf.Session() as sess :\n",
    "        saver.restore(sess, tf.train.latest_checkpoint('./'))\n",
    "        graph = tf.get_default_graph()\n",
    "        num_examples = len(X_test)\n",
    "        accuracy = graph.get_tensor_by_name(\"accuracy/accuracy:0\")\n",
    "        X = graph.get_tensor_by_name(\"input:0\")\n",
    "        y = graph.get_tensor_by_name(\"labels:0\")\n",
    "        dropout = graph.get_tensor_by_name('dropout:0')\n",
    "        total_accuracy = 0\n",
    "        for k in range(0, num_examples,batch_size) :\n",
    "            X_batchT, y_batchT = X_test[k:k+batch_size], y_test[k:k+batch_size]\n",
    "            res_accuracy = sess.run(accuracy, feed_dict={X: X_batchT, y: y_batchT, dropout:0})\n",
    "            total_accuracy += (res_accuracy * len(X_batchT))\n",
    "        print(total_accuracy / num_examples * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Метод классификации принимает \n",
    "# принимает на вход путь к изображени и путь к модели\n",
    "# пример пути к изображени:\"./picture.jpg\"\n",
    "# пример пути к модели \"..../bestmodel\".\n",
    "# метод выводит класс, к которому принадлежит картинка и вероятности принадлежности\n",
    "# ко всем классам.\n",
    "def classification(path_to_img, path_to_model) :\n",
    "    tf.reset_default_graph()\n",
    "    test_img = converting_img(path_to_img)\n",
    "    saver = tf.train.import_meta_graph(path_to_model+\".meta\")\n",
    "    with tf.Session() as sess :\n",
    "        saver.restore(sess, tf.train.latest_checkpoint('./'))\n",
    "        graph = tf.get_default_graph()\n",
    "        predicted = graph.get_tensor_by_name(\"accuracy/prediction:0\")\n",
    "        class_probalities = graph.get_tensor_by_name(\"accuracy/classification:0\")\n",
    "        X = graph.get_tensor_by_name(\"input:0\")\n",
    "        dropout = graph.get_tensor_by_name('dropout:0')\n",
    "        class_prob, pred = sess.run([class_probalities, predicted], feed_dict={X: test_img, dropout:0})                 \n",
    "        print(\"digit:\", pred+1, \"probabilities:\", class_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Метод подготовки картинки для класификации\n",
    "def converting_img(path) :\n",
    "    with tf.Session() as sess:\n",
    "        img = []\n",
    "        convert = tf.image.rgb_to_grayscale(plt.imread(path))\n",
    "        conv_img = sess.run(convert)\n",
    "        resize = tf.image.resize_images(conv_img, [88, 88])\n",
    "        pre_img = np.squeeze(sess.run(resize), 2)\n",
    "        img.append(pre_img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Загрузка данных из уже готовых массивов numpy\n",
    "#X_train, y_train, X_test, y_test = load_prepared_data(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "Поехали\n",
      "\n",
      "Epoch: 1  best accuracy: 63.20653375363877  current accuracy: 63.20653375363877\n",
      "Epoch: 2  best accuracy: 76.61723607641483  current accuracy: 76.61723607641483\n",
      "Epoch: 3  best accuracy: 85.72963686520224  current accuracy: 85.72963686520224\n",
      "Epoch: 3  best accuracy: 85.72963686520224  current accuracy: 84.05329874836191\n",
      "Epoch: 5  best accuracy: 92.77885224315496  current accuracy: 92.77885224315496\n",
      "Epoch: 6  best accuracy: 93.91790212110219  current accuracy: 93.91790212110219\n",
      "Epoch: 7  best accuracy: 96.41091846891969  current accuracy: 96.41091846891969\n",
      "Epoch: 8  best accuracy: 96.64732468222998  current accuracy: 96.64732468222998\n",
      "Epoch: 8  best accuracy: 96.64732468222998  current accuracy: 95.89512187538418\n",
      "Epoch: 10  best accuracy: 97.61444379789917  current accuracy: 97.61444379789917\n",
      "Epoch: 11  best accuracy: 97.76488372184578  current accuracy: 97.76488372184578\n",
      "Epoch: 11  best accuracy: 97.76488372184578  current accuracy: 97.65742677861378\n",
      "Epoch: 12  best accuracy: 97.76488372184578  current accuracy: 74.81194935305103\n",
      "Epoch: 14  best accuracy: 97.8508500637302  current accuracy: 97.8508500637302\n",
      "Epoch: 15  best accuracy: 98.23769701441822  current accuracy: 98.23769701441822\n",
      "Epoch: 16  best accuracy: 98.7320016807775  current accuracy: 98.7320016807775\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-b251814c6e05>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Обучение нейронной сети\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-25-d7febaf45c2d>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(X_train, y_train, X_test, y_test)\u001b[0m\n\u001b[0;32m     40\u001b[0m                 \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ml\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m                 \u001b[0mX_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m                 \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0my_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m             \u001b[0mnum_examples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files11\\Anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    898\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 900\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    901\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files11\\Anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1135\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1136\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files11\\Anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1314\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1316\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1317\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files11\\Anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1320\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1322\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1323\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files11\\Anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1307\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1309\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files11\\Anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1409\u001b[1;33m           run_metadata)\n\u001b[0m\u001b[0;32m   1410\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1411\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Обучение нейронной сети\n",
    "#train(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./bestmodel\n",
      "98.7320016807775\n"
     ]
    }
   ],
   "source": [
    "#Оценка точности модели на проверочном наборе\n",
    "#evaluate(X_test, y_test, r'C:\\Users\\pyroman\\task\\bestmodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Can't load save_path when it is None.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-cf9a389342c9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Классификация одного рисунка\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mclassification\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"C:/Users/pyroman/1.jpg\"\u001b[0m \u001b[1;33m,\u001b[0m\u001b[1;34m\"C:/Users/pyroman/task/model/bestmodel\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-8-2b7de8e63639>\u001b[0m in \u001b[0;36mclassification\u001b[1;34m(path_to_img, path_to_model)\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0msaver\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimport_meta_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_to_model\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\".meta\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msess\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0msaver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlatest_checkpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[0mgraph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mpredicted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_tensor_by_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"accuracy/prediction:0\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files11\\Anaconda\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\u001b[0m in \u001b[0;36mrestore\u001b[1;34m(self, sess, save_path)\u001b[0m\n\u001b[0;32m   1794\u001b[0m       \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1795\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msave_path\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1796\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Can't load save_path when it is None.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1797\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Restoring parameters from %s\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1798\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Can't load save_path when it is None."
     ]
    }
   ],
   "source": [
    "#Классификация одного рисунка\n",
    "#classification(\"C:/Users/pyroman/1.jpg\" ,\"C:/Users/pyroman/task/bestmodel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook task.ipynb to script\n",
      "[NbConvertApp] Writing 15643 bytes to task.py\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to script task.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "digit: [7] probabilities: [[6.8942668e-14 1.0150678e-13 1.4211731e-05 3.5834855e-03 7.3180503e-11\n",
      "  9.1218457e-02 9.0517962e-01 4.1785834e-06]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files11\\Anaconda\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Traceback (most recent call last):\n",
      "  File \"task.py\", line 467, in <module>\n",
      "    get_ipython().system('jupyter nbconvert --to script task.ipynb')\n",
      "NameError: name 'get_ipython' is not defined\n",
      "2018-08-07 11:26:30.360320: I C:\\users\\nwani\\_bazel_nwani\\mmtm6wb6\\execroot\\org_tensorflow\\tensorflow\\core\\platform\\cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX\n",
      "2018-08-07 11:26:30.711425: I C:\\users\\nwani\\_bazel_nwani\\mmtm6wb6\\execroot\\org_tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1356] Found device 0 with properties: \n",
      "name: GeForce GTX 1050 major: 6 minor: 1 memoryClockRate(GHz): 1.455\n",
      "pciBusID: 0000:01:00.0\n",
      "totalMemory: 2.00GiB freeMemory: 1.72GiB\n",
      "2018-08-07 11:26:30.711457: I C:\\users\\nwani\\_bazel_nwani\\mmtm6wb6\\execroot\\org_tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1435] Adding visible gpu devices: 0\n",
      "2018-08-07 11:26:31.432178: I C:\\users\\nwani\\_bazel_nwani\\mmtm6wb6\\execroot\\org_tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:923] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2018-08-07 11:26:31.432192: I C:\\users\\nwani\\_bazel_nwani\\mmtm6wb6\\execroot\\org_tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:929]      0 \n",
      "2018-08-07 11:26:31.432199: I C:\\users\\nwani\\_bazel_nwani\\mmtm6wb6\\execroot\\org_tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:942] 0:   N \n",
      "2018-08-07 11:26:31.432305: I C:\\users\\nwani\\_bazel_nwani\\mmtm6wb6\\execroot\\org_tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 1476 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050, pci bus id: 0000:01:00.0, compute capability: 6.1)\n",
      "2018-08-07 11:26:31.699322: I C:\\users\\nwani\\_bazel_nwani\\mmtm6wb6\\execroot\\org_tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1435] Adding visible gpu devices: 0\n",
      "2018-08-07 11:26:31.699387: I C:\\users\\nwani\\_bazel_nwani\\mmtm6wb6\\execroot\\org_tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:923] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2018-08-07 11:26:31.699393: I C:\\users\\nwani\\_bazel_nwani\\mmtm6wb6\\execroot\\org_tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:929]      0 \n",
      "2018-08-07 11:26:31.699396: I C:\\users\\nwani\\_bazel_nwani\\mmtm6wb6\\execroot\\org_tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:942] 0:   N \n",
      "2018-08-07 11:26:31.699449: I C:\\users\\nwani\\_bazel_nwani\\mmtm6wb6\\execroot\\org_tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 1476 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050, pci bus id: 0000:01:00.0, compute capability: 6.1)\n"
     ]
    }
   ],
   "source": [
    "!python task.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(str(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[1, 2, 3]'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
